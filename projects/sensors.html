<!doctype html>
<!-- The Time Machine GitHub pages theme was designed and developed by Jon Rohan, on Feb 7, 2012. -->
<!-- Follow him for fun. http://twitter.com/jonrohan. Tail his code on http://github.com/jonrohan -->
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <link rel="icon" type="image/x-icon" href="../images/favicon.ico">

  <link rel="stylesheet" href="../stylesheets/stylesheet.css" media="screen"/>
  <link rel="stylesheet" href="../stylesheets/pygment_trac.css"/>
  <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
  <script type="text/javascript" src="javascripts/script.js"></script>

  <title>Ryan Young</title>
  <meta name="description" content="Ryan Young&#39;s website">

  <meta name="viewport" content="width=device-width,initial-scale=1">

</head>

<body>

  <div class="wrapper">
    <header>
      <h1 class="title"><a href="../index.html">Ryan Young</a></h1>
    </header>
    <div id="container">
      <p class="tagline">Sensor integration on HUBO</p>
      <div id="main" role="main">
        <div class="download-bar">
        <div class="inner">
          <a href="https://github.com/RyanYoung25" class="code">View Ryan Young on GitHub</a>
        </div>
        <span class="blc"></span><span class="trc"></span>
        </div>
        <article class="markdown-body">

          <h4><a name="external-sensors" class="anchor" href="#external-sensors"><span class="octicon octicon-link"></span></a>External Sensors</h4>

          <p>Originally the HUBO robot did not have sensors capable of effectively interacting with the world around it. With the development of MAESTOR I was able to start integrating off the shelf sensors onto HUBO which makes it possible for HUBO to have more knowledge about the world around it. The sensors that we decided to integrate were high quality microphones, an RGB-Depth camera, and high resolution tactile sensors. These sensors correspond to human senses such as hearing, sight, and the sense of touch. </p>

          <h5><a name="Microphones" class="anchor" href="#external-sensors"><span class="octicon octicon-link"></span></a>Microphones</h5>

          <img src="../images/mics.jpg"></img>

          <p>The original microphone that HUBO had was a single mono microphone that was not very sensitive. Because of this HUBO couldn't do very much audio processing. With the new stereo microphones that HUBO has, we are able to have HUBO listen more like a person does. HUBO can use its new microphones to do things such as automatic drum calibration, <a href="https://youtu.be/p4ANXkvhypk"> drum mimicking,</a> <a href="https://www.youtube.com/watch?v=eGJKxyRcVko"> audio fingerprinting and dancing,</a> and sound localization. These are only a few examples of the things that HUBO can do with his new sense of hearing and the list continues to grow every day. </p>

          <h5><a name="Asus Xtion Pro" class="anchor" href="#external-sensors"><span class="octicon octicon-link"></span></a>RGB-Depth Sensor</h5>

          <img src="../images/camera.png"></img>

          <p>Out of the box HUBO also did not have very much vision. HUBO had a single, very low resolution web cam mounted at the top of his head. We've 3d printed a head for HUBO that holds an Asus Xtion Pro RGB-Depth camera which give HUBO a 3d view of the world in front of it. The Asus Xtion Pro is very similar to a kinect camera and has the ability to get depth data about objects in front of it. With the depth data we are able to do a few things such as <a href="https://www.youtube.com/watch?v=RK4W_aYcOCg">facial tracking</a> courtesy of the COB people tracker, and very recently gesture classification thanks to some machine learning research I am pursuing.</p>

          <h5><a name="BioTac" class="anchor" href="#external-sensors"><span class="octicon octicon-link"></span></a>BioTacs</h5>
          
          <img src="../images/biotac.jpg"></img>

          <p>Lastly, out of the box HUBO did not have any sense of touch. HUBO only had four force torque sensors, two in the wrists, and two in the feet to give any force feedback. These sensors were not very helpful for doing task that require dexterity like picking up objects. Because of this we decided to equip HUBO with very high resolution tactile sensors called BioTacs capable of sensing pressure, vibration, and temperature. Unfortunately, due to the design of the fingers and their unreliability I have not had the opportunity to extensively try grasping things with the new fingers. I have however worked to create software that allowed them to be used on HUBO so that other researchers that have HUBO will be able to use them as well.</p>

        </article>
      </div>
    </div>
    <footer>
      <div class="owner">

      <p><a href="https://github.com/RyanYoung25" class="avatar"><img src="https://avatars3.githubusercontent.com/u/3376419?s=60" width="48" height="48"/></a>View <a href="https://github.com/RyanYoung25">RyanYoung25</a> on <a href="https://www.github.com">GitHub</a></p>

      </div>
      <div class="creds">
        <small>This page generated using <a href="http://pages.github.com/">GitHub Pages</a><br/>theme by <a href="https://twitter.com/jonrohan/">Jon Rohan</a></small>
      </div>
    </footer>
  </div>
  <div class="current-section">
    <a href="#top">Scroll to top</a>
    <a href="https://github.com/RyanYoung25/RyanYoung25.github.io/tarball/master" class="tar">tar</a><a href="https://github.com/RyanYoung25/RyanYoung25.github.io/zipball/master" class="zip">zip</a><a href="" class="code">source code</a>
    <p class="name"></p>
  </div>

  
</body>
</html>
